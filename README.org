#+TITLE: libdivvun
#+STARTUP: showall

#+CAPTION: Build Status
[[https://travis-ci.org/divvun/libdivvun][https://travis-ci.org/divvun/libdivvun.svg]]

#+CAPTION: Coverity static analysis
[[https://scan.coverity.com/projects/divvun-divvun-gramcheck][https://scan.coverity.com/projects/13737/badge.svg]]

* Description

This repository contains the library =libdivvun=, and four main
executables:

=divvun-checker=: This program opens a grammar checker pipeline XML
specification and lets you run grammar checking on strings. It can
also open zip files containing the XML and all required language
data. The C++ library =libdivvun= (headers installed to
=$PREFIX/include/divvun/*.hpp=) allows for the same features.


=divvun-suggest=: This program does FST lookup on forms specified as
Constraint Grammar format readings, and looks up error-tags in an XML
file with human-readable messages. It is meant to be used as a late
stage of a grammar checker pipeline.

The main output format of =divvun-suggest= is JSON, although it can
also simply annotate readings in CG stream format.


=divvun-cgspell=: This program spells unknown word forms from
Constraint Grammar format readings, adding them as new readings.


=divvun-blanktag=: This program takes an FST as argument, reads CG
input and uses the FST to add readings to cohorts that match on the
wordform surrounded by the preceding and following blanks. Use cases
include adding error tags that are dependent on spaces before/after,
or tagging the first word after a linebreak or certain formatting.


There are also some helper programs for validating XML
(=divvun-validate-suggest=, =divvun-validate-pipespec=,
=divvun-gen-xmlschemas=) and for generating shell scripts from
pipeline specifications (=divvun-gen-sh=).

* Install from packages

Tino Didriksen has kindly packaged this as both =.deb= and =.rpm=.

For =.deb= (Debian, Ubuntu and derivatives), add the repo and install
the package with:

#+BEGIN_SRC sh
wget https://apertium.projectjj.com/apt/install-nightly.sh
sudo bash install-nightly.sh
sudo apt install divvun-gramcheck
#+END_SRC

For =.rpm= (openSUSE, Fedora, CentOS and derivatives), add the repo
and install the package with:

#+BEGIN_SRC sh
wget https://apertium.projectjj.com/rpm/install-nightly.sh
sudo bash install-nightly.sh
sudo dnf install divvun-gramcheck
#+END_SRC

(See also the [[https://apertium.projectjj.com/apt/logs/divvun-gramcheck/][deb build logs]] and [[https://build.opensuse.org/package/show/home:TinoDidriksen:nightly/divvun-gramcheck][rpm build status]].)

* Simple build from git on Mac

There is a script that will download prerequisites and compile and
install for Mac.

You don't even need to checkout this repository; just run:
#+BEGIN_SRC sh
curl https://raw.githubusercontent.com/divvun/divvun-gramcheck/master/scripts/mac-build | bash
#+END_SRC

and enter your =sudo= password when it asks you to.

It does not (yet) enable =divvun-checker=, since that has yet more
dependencies. It assumes you've got =xmllint= installed.

* Prerequisites

/Note: Mac users probably just want to follow the steps in [[*Simple build from git on Mac][Simple
build from git on Mac]]./

This section lists the prerequisites for building the various tools in
this package.

** For just =divvun-suggest= and =divvun-blanktag=

- gcc >=5.0.0 with libstdc++-5-dev (or similarly recent version of
  clang, with full C++11 support)
- libxml2-utils (just for xmllint)
- libhfst >=3.12.2
- libpugixml >=1.7.2 (optional)

Tested with gcc-5.2.0, gcc-5.3.1 and clang-703.0.29. On Mac OS X, the
newest XCode includes a modern C++ compiler.

If you can't easily install libpugixml, you can run
[[file:scripts/get-pugixml-and-build][scripts/get-pugixml-and-build]] which will download libpugixml into this
directory, build that (with cmake) and configure this program to use
that library. Alternatively, you can run ./configure with
=--disable-xml= if you don't care about human-readable error messages.

** If you also want =divvun-gramcheck=

- gcc >=5.0.0 with libstdc++-5-dev (or similarly recent version of
  clang, with full C++11 support)
- libxml2-utils (just for xmllint)
- libhfst >=3.12.2
- libpugixml >=1.7.2
- libcg3-dev >=1.1.2.12327
- libarchive >=3.2.2-2

Tested with gcc-5.2.0, gcc-5.3.1 and clang-703.0.29. On Mac OS X, the
newest XCode includes a modern C++ compiler.

If you can't easily install libpugixml, you can run
[[file:scripts/get-pugixml-and-build][scripts/get-pugixml-and-build]] which will download libpugixml into this
directory, build that (with cmake) and configure this program to use
that library.

Now when building, pass =--enable-checker= to configure.

** If you also want =divvun-cgspell=

- hfst-ospell-dev >=0.4.5 (compiled with either libxml or tinyxml)

You can pass =--enable-cgspell= to =./configure= if you would like to
get an error if any of the =divvun-cgspell= dependencies are missing.

** If you also want the Python library

The Python 3 library is used by the LibreOffice plugin. It will build
if it finds both of:

- SWIG >=3.0 (install =python-swig= if you're using MacPorts)
- Python >=3.0

You can pass =--enable-python-bindings= to =./configure= if you would
like to get an error if any of the =divvun-python-bindings=
dependencies are missing.


* Building

#+BEGIN_SRC sh
./autogen.sh
./configure --enable-checker  # or just "./configure" if you don't need divvun-gramcheck
make
make install # with sudo if you didn't specify a --prefix to ./configure
#+END_SRC


On OS X, you may have to do this:

#+BEGIN_SRC sh
sudo port install pugixml
export CC=clang CXX=clang++ "CXXFLAGS=-std=gnu++11 -stdlib=libc++"
./autogen.sh
./configure  LDFLAGS=-L/opt/local/lib --enable-checker
make
make install # with sudo if you didn't specify a --prefix to ./configure
#+END_SRC

* Command-line usage

** =divvun-suggest=

=divvun-suggest= takes two arguments: a generator FST (in HFST
optimised lookup format), and an error message XML file (see [[https://gtsvn.uit.no/langtech/trunk/langs/sme/tools/grammarcheckers/errors.xml][the one
for North Saami]] for an example), with input/output as stdin and
stdout:

#+BEGIN_SRC sh
src/divvun-suggest --json generator-gt-norm.hfstol errors.xml < input > output
#+END_SRC


More typically, it'll be in a pipeline after various runs of =vislcg3=:

#+BEGIN_SRC sh
echo words go here | hfst-tokenise --giella-cg tokeniser.pmhfst | â€¦ | vislcg3 â€¦ \
  | divvun-suggest --json generator-gt-norm.hfstol errors.xml
#+END_SRC


** =divvun-blanktag=

=divvun-blanktag= takes one argument: an FST (in HFST
optimised lookup format), with input/output as stdin and
stdout:

#+BEGIN_SRC sh
src/divvun-blanktag analyser.hfstol < input > output
#+END_SRC


More typically, it'll be in a pipeline after =cg-mwesplit=:

#+BEGIN_SRC sh
echo words go here | hfst-tokenise â€¦ | â€¦ | cg-mwesplit \
  | src/divvun-blanktag analyser.hfstol < input > output
#+END_SRC

See the file [[file:test/blanktag/blanktagger.xfst][test/blanktag/blanktagger.xfst]] for an example blank
tagging FST (the other files in [[file:test/blanktag][test/blanktag]] show test input and
expected output, as well as how to compile the FST).


** =divvun-cgspell=

=divvun-cgspell= takes options similar to [[https://github.com/hfst/hfst-ospell/][hfst-ospell]]. You can give it
a single zhfst speller archive with the =-a= option, or specify
unzipped error model and lexicon with =-m= and =-l= options.

There are some options for limiting suggestions too, see
=--help=. You'll probably want to use =--limit= at least.

#+BEGIN_SRC sh
src/divvun-cgspell --limit 5 se.zhfst < input > output
#+END_SRC


More typically, it'll be in a pipeline before/after various runs of =vislcg3=:

#+BEGIN_SRC sh
echo words go here | hfst-tokenise --giella-cg tokeniser.pmhfst | â€¦ | vislcg3 â€¦ \
  | src/divvun-cgspell --limit 5 se.zhfst | vislcg3 â€¦
#+END_SRC

You can also use it with unzipped, plain analyser and error model, e.g.

#+BEGIN_SRC sh
src/divvun-cgspell --limit 5 -l analyser.hfstol -m errmodel.hfst < input > output
#+END_SRC


** =divvun-checker=

=divvun-checker= is an example command-line interface to =libdivvun=.
You can use it to test a =pipespec.xml= or a zip archive containing
both the pipespec and langauge data, e.g.

#+BEGIN_SRC sh
$ divvun-checker -a sme.zhfst
Please specify a pipeline variant with the -n/--variant option. Available variants in archive:
smegram
smepunct

$ echo ballat oÄ‘Ä‘a dieÄ‘uiguin | src/divvun-checker -a sme.zhfst -n smegram
{"errs":[["dieÄ‘uiguin",12,22,"msyn-valency-loc-com","Wrong valency or something",["diehtukorrekt"]]],"text":"ballat oÄ‘Ä‘a dieÄ‘uiguin"}

$ divvun-checker -s pipespec.xml
Please specify a pipeline variant with the -n/--variant option. Available variants in pipespec:
smegram
smepunct

$ echo ballat oÄ‘Ä‘a dieÄ‘uiguin | src/divvun-checker -s pipespec.xml -n smegram
{"errs":[["dieÄ‘uiguin",12,22,"msyn-valency-loc-com","Wrong valency or something",["diehtukorrekt"]]],"text":"ballat oÄ‘Ä‘a dieÄ‘uiguin"}
#+END_SRC

When using the =-s/--spec pipespec.xml= option, relative paths in the
pipespec are relative to the current directory.

See the =test/= folder for an example of zipped archives.

See the [[file:examples/using-checker-lib-from-cpp][examples folder]] for how to link into divvun-gramcheck and use
it as a library, getting out either the JSON-formatted list of errors,
or a simple [[file:src/checkertypes.hpp::struct%20Err%20{][data structure]] that contains the same information as the
JSON. The next section describes the JSON format.


* JSON format
The JSON output of =divvun-suggest= is meant to be sent to a client
such as [[https://github.com/divvun/divvun-webdemo]]. The current format
is:

: {errs:[[str:string, beg:number, end:number, typ:string, exp:string, [rep:string]]], text:string}

The string =text= is the input, for sanity-checking.

The array-of-arrays =errs= has one array per error. Within each
error-array, =beg/end= are offsets in =text=, =typ= is the (internal)
error type, =exp= is the human-readable explanation, and each =rep= is
a possible suggestion for replacement of the text between =beg/end= in
=text=.

The index =beg= is inclusive, =end= exclusive, and both indices are
based on a UTF-16 encoding (which is what JavaScript uses, so e.g. the
emoji "ðŸ‡³ðŸ‡´" will increase the index of the following errors by 4).

Example output:

#+BEGIN_SRC js
  {
    "errs": [
      [
        "badjel",
        37,
        43,
        "lex-bokte-not-badjel",
        "\"bokte\" iige \"badjel\"",
        [
          "bokte"
        ]
      ]
    ],
    "text": "ðŸ‡³ðŸ‡´sÃ¡ddejuvvot bÃ¡hpirat interneahta badjel.\n"
  }
#+END_SRC

* Pipespec XML

The =divvun-checker= program and =libdivvun= (=divvun/checker.hpp=)
API has an XML format for specifying what programs go into the checker
pipelines, and metadata about the pipelines.

A =pipespec.xml= defines a set of grammar checker (or really any text
processing) pipelines.

There is a main language for each pipespec, but individual pipelines
may override with variants.

Each pipeline may define certain a set of mutually exclusive (radio
button) preferences, and if there's a =<suggest>= element referring to
an =errors.xml= file in the pipeline, error tags from that may be used
to populate UI's for hiding certain errors.



** Mapping from XML preferences to UI

The mapping from preferences in the XML to a user interface should be
possible to do automatically, so the UI writer doesn't have to know
anything about what preferences the pipespec defines, but can just ask
the API for a list of preferences.

Preferences in the UI are either checkboxes [X] or radio buttons (*).


We might for example get the following preferences UI:
: (*) Nordsamisk, Sverige
: ( ) Nordsamisk, Noreg
: â€¦
: [X] Punctuation
:     (*) punktum som tusenskilje
:     ( ) mellomrom som tusenskilje
: [-] Grammar errors
:     [X] ekteordsfeil
:     [ ] syntaksfeil


Here, the available languages are scraped from the pipespec.xml
using =//pipeline/@language=.

A language is selected, so we create a Main Category of error types from
: pipespec.xml //[@language=Sverige|@language=""]/prefs/@type
: pipespec.xml //pipeline[@language=Sverige|@language=""]/@type
: errors.xml   //default/@type
: errors.xml   //error/@type

in this case giving the set { Punctuation, Grammar errors }.

One Main Category type is Punctuation; the radio buttons under
this main category are those defined in
: pipespec.xml //prefs[@type="Punctuation"]

The other Main Category type is Grammar errors; maybe we didn't have anything
in
: pipespec.xml //prefs[@type="Grammar errors"]
but there are checkboxes for errors that we can hide in
: errors.xml //defaults/default/title

It should be possible for the UI to hide which underlying
=<pipeline>='s are chosen, and only show the preferences (picking a
pipeline based on preferences). But there is an edge case: Say the
pipe named smegram_SE with language sme_SE and main type "Grammar
errors" has a
: pref[@type="Punctuation"]
and there's another pipe named smepunct with main type "Punctuation".
Now, assuming we select the language sme_SE, we'll never use smepunct,
since smegram defines error types that smepunct doesn't, but not the
other way around. Hopefully this is not a problem in practice.


* Writing grammar checkers

Grammar checkers written for use in =libdivvun= consist of a
pipeline, at a high level typically looking like:

: tokenisation/morphology | multiword handling | disambiguation | error rules | generation

There are often other modules in here too, e.g. for adding spelling
suggestions, annotating valency, disambiguation and splitting
multiwords, or annotating surrounding whitespace.

Below we go through some of the different parts of the checker, using
the Giellatekno/Divvun North Saami package (from
https://victorio.uit.no/langtech/trunk/langs/sme/) as an example.

** XML pipeline specification

Each grammar checker needs a pipeline specification with all the
different modules and their data files in order. This is written in a
file =pipespec.xml=, which should follow the [[src/pipespec.dtd][pipespec.dtd]]. Each such
file may have several =<pipeline>= elements (in case there are
alternative pipeline variants in your grammar checker package), with a
name and some metadata.

Here is the =pipespec.xml= for North Saami:

#+begin_src xml
  <pipespec language="se"
            developer="Divvun"
            copyright="â€¦"
            version="0.42"
            contact="Divvun divvun@uit.no">

    <pipeline name="smegram"
              language="se"
              type="Grammar error">
      <tokenize><arg n="tokeniser-gramcheck-gt-desc.pmhfst"/></tokenize>
      <cg><arg n="valency.bin"/></cg>
      <cg><arg n="mwe-dis.bin"/></cg>
      <mwesplit/>
      <blanktag>
        <arg n="analyser-gt-whitespace.hfst"/>
      </blanktag>
      <cgspell>
        <arg n="errmodel.default.hfst"/>
        <arg n="acceptor.default.hfst"/>
      </cgspell>
      <cg><arg n="disambiguator.bin"/></cg>
      <cg><arg n="grammarchecker.bin"/></cg>
      <suggest>
        <arg n="generator-gt-norm.hfstol"/>
        <arg n="errors.xml"/>
      </suggest>
    </pipeline>

    <!-- other variants ommitted -->

  </pipespec>
#+end_src

This is what happens when text is sent through the =smegram= pipeline:

- First, =<tokenize>= turns plain text into morphologically analysed
  tokens, using an FST compiled with =hfst-pmatch2fst=. These tokens
  may be ambiguous both wrt. to morphology and tokenisation.
- Then, a =<cg>= module adds valency tags to readings, enriching the
  morphological analysis with context-sensitive information on
  argument structure.
- Another =<cg>= module disambiguates cohorts that are ambiguous
  wrt. tokenisation, like multiwords and punctuation.
- The =<mwesplit>= module splits now-disambiguated multiwords into
  separate tokens.
- Then =<blanktag>= adds some tags to readings based on the
  surrounding whitespace (or other types of non-token
  blanks/formatting), using an FST which matches sequences of
  blankâ€“wordformâ€“blank.
- The =<cgspell>= module adds readings with spelling suggestions to
  unknown words. The suggestions appear as wordform-tags.
- Then a =<cg>= disambiguator, with rules modified a bit to let
  through more errors.
- The main =<cg>= grammar checker module can now add error tags to
  readings, as well as new readings for generating suggestions, or
  special tags for deleting words or expanding underlines (and, as in
  the other =<cg>= modules, we can use the full range of CG features
  to add information that may be helpful in these tasks, such as
  dependency annotation and semantic role analysis)
- Finally, =<suggest>= uses a generator FST to turn suggestion
  readings into forms, and an XML file of error descriptions to look
  up error messages from the tags added by the =<cg>= grammar checker
  module. These are used to output errors with suggestions, as well as
  readable error messages and the correct indices for underlines.

The program =divvun-gen-sh= in this package creates shell scripts from
the specification that you can use to test your grammar checker. In
the North Saami checker, these should appear in
=tools/grammarcheckers/modes= when you type =make=, but you can also
create a single script for the above pipeline manually. If we do
=divvun-gen-sh -s pipespec.xml -n smegram > test.sh= with the above
XML, =test.sh= will contain something like

#+begin_src sh
#!/bin/sh

hfst-tokenise -g '/home/me/gtsvn/langs/sme/tools/grammarcheckers/tokeniser-gramcheck-gt-desc.pmhfst' \
 | vislcg3 -g '/home/me/gtsvn/langs/sme/tools/grammarcheckers/valency.bin' \
 | vislcg3 -g '/home/me/gtsvn/langs/sme/tools/grammarcheckers/mwe-dis.bin' \
 | cg-mwesplit \
 | divvun-blanktag '/home/me/gtsvn/langs/sme/tools/grammarcheckers/analyser-gt-whitespace.hfst' \
 | divvun-cgspell '/home/me/gtsvn/langs/sme/tools/grammarcheckers/errmodel.default.hfst' '/home/me/gtsvn/langs/sme/tools/grammarcheckers/acceptor.default.hfst' \
 | vislcg3 -g '/home/me/gtsvn/langs/sme/tools/grammarcheckers/disambiguator.bin' \
 | vislcg3 -g '/home/me/gtsvn/langs/sme/tools/grammarcheckers/grammarchecker.bin' \
 | divvun-suggest '/home/me/gtsvn/langs/sme/tools/grammarcheckers/generator-gt-norm.hfstol' '/home/me/gtsvn/langs/sme/tools/grammarcheckers/errors.xml'
#+end_src

We can send words through this pipeline with =echo "words here" | sh
test.sh=.

Using =divvun-gen-sh= manually like this is good for checking if
you've written your XML correctly, but if you're working within the
Giellatekno projects, you'll typically just type =make= and use the
scripts that end up in =modes=.

Do
#+begin_src sh
$ ls modes
#+end_src
in =tools/grammarcheckers= to list all the scripts. These contain not
just the full pipeline (for every =<pipeline>= in the XML), but also
"debug" versions that are chopped off at various points (with numbers
to show how far they go), as well as versions with CG rule tracing
turned on. So if you'd like to check up until disambiguation, before
the =grammarchecker= CG, you'd do something like

#+begin_src sh
echo "words go here" | sh modes/trace-smegram6-disam.mode
#+end_src

** Simple grammarchecker.cg3 rules

In our North Saami checker, the
#+begin_src xml
<cg><arg n="grammarchecker.bin"></cg>
#+end_src
file is created with from the source file
=$GTHOME/langs/sme/tools/grammarcheckers/grammarchecker.cg3=, which
adds error tags and suggestion-readings.

A simple rule looks like:

#+begin_src cg
ADD:msyn-hallan (&real-hallan) TARGET (Imprt Pl1 Dial/-KJ) IF (0 HALLA-PASS-V) (NEGATE *1 ("!")) ;
#+end_src
This simply adds an error tag =real-hallan= to words that are tagged
=Imprt Pl1 Dial/-KJ= and match the context conditions after the
=IF=. This will put an underline under the word in the user
interface. If =errors.xml= in the same folder has a nice description
for that tag, the user will see that description in the user
interface.

We can add a suggestion as well with a =COPY= rule:
#+begin_src cg
COPY:msyn-hallan (Inf &SUGGEST) EXCEPT (Imprt Pl1 Dial/-KJ) TARGET (Imprt Pl1 Dial/-KJ &real-hallan) ;
#+end_src
This creates a new reading where the tags =Imprt Pl1 Dial/-KJ= have
been changed into =Inf &SUGGEST= (and other tags are unchanged). The
=&SUGGEST= tag is necessary to get =divvun-suggest= (the =<suggest>=
module) to try to generate a form from that reading. It is smart
enough to skip things like weights, tracing and syntax tags when
trying to suggest, but all morphological tags need to be correct and
in the right order for generation to work.

-----

You can refer to the word form of the "central" cohort of the error
using =$1= in errors.xml, e.g.

#+begin_src xml
      <description xml:lang="en">The word "$1" seems to be in the wrong case.</description>
#+end_src

-----

To refer to other words, you add relations named =$2= and so on:
#+begin_src cg
ADDRELATION ($2) Ess TO (*-1 ("dego" &syn-not-dego) BARRIER Ess);
#+end_src

which you can refer to just like with =$1=:

#+begin_src xml
      <title xml:lang="en">there should not be "$2" if "$1" is essive</title>
#+end_src

** Deleting words

If you want to delete a word from a CG rule, it's typically enough to
add an error tag to the word you want to /keep/, and add a relation
=DELETE1= to the word you want to delete. This will make an underline
that covers both those words, where the suggestion is the same string
without the target of the =DELETE1= relation.

#+begin_src cg
  ADD (&one-word-too-many) KeepThisWord;
  ADDRELATION (DELETE1) KeepThisWord TO (-1 DeleteThisWord);
#+end_src

The cohort matching =KeepThisWord= is now the central one of the
error, so if e.g. =errors.xml= uses templates like =Don't use "$2"
before "$1"=, the word form of =KeepThisWord= will be substituted for
=$1=.

You may delete more words from the same suggestion using =DELETE2=
etc.

-----

However, some times you have several possible suggestions on the same
word, which might partially overlap. For example, you might also have

#+begin_src cg
  ADD (&other-error) KeepThisWord;
  COPY (Nom &other-error) EXCEPT (Acc) TARGET (&other-error) ;
#+end_src

where you want to keep the suggestions for =&one-word-too-many=
separate from the suggestions for =&other-error=.

Unfortunately, relations in CG are cohort-to-cohort, not
reading-to-reading. The workaround is to put the error tag also on the
relation target (the word to be deleted), along with the =&LINK= tag
to say that this is not the central word of the error:

#+begin_src cg
  ADD (&LINK &one-word-too-many) DeleteThisWord IF (1 KeepThisWord);
#+end_src

Without =&LINK=, this would be treated as a separate error, while
without =&one-word-too-many=, we would suggest deleting this word in
the suggestions for =&other-error= too.

Similarly, the =&SUGGEST= reading for the =&other-error= retains the
=&other-error= tag, which avoids generating that suggestion for the
=&one-word-too-many= error.

A real example of this in the North Saami checker is the error
=dego lÃ¡vvomuorran=, which has the suggestions =lÃ¡vvomuorran= or =dego
lÃ¡vvomuorra= â€“ one error type alters just the form, and one removes
just the preceding word.

** Adding words

To add a word as a suggestion, use =ADDCOHORT=, adding both reading
tags (lemma, part-of-speech etc.), a wordform tag (including a space)
and =&ADDED= to mark it as something that didn't appear in the input;
and then a =LEFT= or =RIGHT= relation from the central cohort of the
error to the added word:

#+begin_src cg
  ADD (&msyn-valency-go-not-fs) IF (â€¦);
  ADDCOHORT ("<go >" "go" CS &ADDED &msyn-valency-go-not-fs) BEFORE &msyn-valency-go-not-fs;
  ADDRELATION (LEFT) (&msyn-valency-go-not-fs) TO (-1 (&ADDED)) ;
#+end_src

Because of =&ADDED=, =divvun-suggest= will treat this as a non-central
word of the error (just like with the =&LINK= tag).

Note that we include the space in the wordform, and we put it at the
/end/ of the wordform. This is because vislcg3 always adds new cohorts
/after/ the blank of the preceding cohort. In some cases, e.g. with
punctuation, we want the new cohort to come before the blank of the
preceding cohort; then we use the tag =&ADDED-BEFORE-BLANK=, and
=divvun-suggest= will ensure it ends up in the right place, e.g.:

#+begin_src cg
  ADD:punct-rihkku (&punct-rihkku) TARGET (Inf) IF (-1 Inf LINK -1 COMMA LINK -1 Inf â€¦);
  ADDCOHORT:punct-rihkku ("<,>" "," CLB &ADDED-BEFORE-BLANK &punct-rihkku) BEFORE (V &punct-rihkku) IF â€¦;
  ADDRELATION (LEFT) (&punct-rihkku) TO (-1 (&ADDED-BEFORE-BLANK)) ;
#+end_src

will give a suggestion that covers the space before the infinitive.

** Including spelling errors

To use the =divvun-cgspell= module, you need a spelling acceptor
(dictionary) FST and error model FST. These are the same format as the
files used by [[https://github.com/hfst/hfst-ospell/][hfst-ospell]]. The speller isn't yet used to handle
real-word errors, just adding suggestions to unknowns.

The =divvun-cgspell= module should go before disambiguation in the
pipeline, so the disambiguator can pick the best suggestion in
context.

The module adds the tag =<spelled>= to any suggestions. The speller
module itself doesn't take any context into account, that's for later
steps to handle. As an example, you might have this unknown word as
input to the speller module:

#+begin_src cg
"<coffe>"
	"coffe" ?
#+end_src

To which the output from the speller might be

#+begin_src cg
"<coffes>"
	"coffes" ?
	"coffee" N Sg <W:37.3018> <WA:17.3018> <spelled> "<coffee>"
	"coffee" N Pl <W:37.3018> <WA:17.3018> <spelled> "<coffees>"
	"coffer" N Pl <W:39.1010> <WA:17.3018> <spelled> "<coffers>"
	"Coffey" N Prop <W:40.0000> <WA:18.1800> <spelled> "<Coffey>"
#+end_src

The /form/ to be suggested is included as a "wordform-tag" at the very
end of each reading from the speller.

Now the later CG stages can use the context of this cohort to pick
more relevant suggestions (e.g. if the word to the left was "a", we
might want to =REMOVE= the plurals or even =SELECT= the singulars). We
could also =ADD/MAP= some relevant tags or relations.

Note that the readings added by the speller don't include any error
tags (tags with =&= in front). To turn these readings into error
underlines and actually show the suggestions, add a rule like

#+begin_src cg
  ADD (&typo &SUGGESTWF) (<spelled>) ;
#+end_src

to the grammar checker CG. The reason we add =&SUGGESTWF= and not
=&SUGGEST= is that we're using the wordform-tag directly as the
suggestion, and not sending each analysis through the generator (as
=&SUGGEST= would do). So if, after disambiguation and grammarchecker
CG's, we had

#+begin_src cg
"<coffes>"
	"coffee" N Pl <W:37.3018> <WA:17.3018> <spelled> "<coffees>" &typo &SUGGESTWF
	"coffer" N Pl <W:39.1010> <WA:17.3018> <spelled> "<coffers>" &typo &SUGGESTWF
#+end_src

then the final =divvun-suggest= step would simply use the contents of
the tags
#+begin_src cg
"<coffers>"
"<coffees>"
#+end_src
to create the suggestion-list, without bothering with generating from
#+begin_src cg
"coffee" N Pl
"coffer" N Pl
#+end_src
This makes the system more robust in case the speller lexicon differs
from the regular suggestion generator, and saves some duplicate work.

** Summary of special tags and relations
*** Tags

- =&SUGGEST= on a reading means that =divvun-suggest= should try to
  generate this reading into a form for suggestions, using the
  generator FST. See [[*Simple grammarchecker.cg3 rules][Simple grammarchecker.cg3 rules]].
- =&SUGGESTWF= on a reading means that =divvun-suggest= should use the
  reading's wordform-tag (e.g. a tag like ="<Cupertino>"= on a
  /reading/, not as the first line of a cohort) as a suggestion.
  See [[*Including spelling errors][Including spelling errors]].
- =<spelled>= is added by =divvun-cgspell= to any suggestions it
  makes. See [[*Including spelling errors][Including spelling errors]].
- =&LINK= makes a cohort non-central in that error, see [[*Deleting words][Deleting words]].
- =&ADDED= means this cohort was added (typically with =ADDCOHORT=)
  and should be a part of the suggestion for the error. It will appear
  after the blank of the preceding cohort, and will not be the central
  cohort of the error. See [[*Adding words][Adding words]].
- =&ADDED-BEFORE-BLANK= is like =&ADDED=, except that it appears
  before the blank of the preceding cohort.
- Any other tag starting with =&= is an error type tag,
  e.g. =&real-hallan= or =&punct-rihkku=, defined by the CG rule
  author. It should also appear in =errors.xml= (without the initial
  =&=) with a human-readable error message.


*** Relations

- =LEFT= and =RIGHT= are used to extend the underline to added
  cohorts; see [[*Adding words][Adding words]].
- =DELETE1= (and =DELETE2= etc.) are used to say that a word in the
  context of this error should be deleted in the suggestion. See [[*Deleting words][Deleting words]].
- =$2= (and =$3= etc.) are used to make wordforms in the context
  available to human-readable error messages in =errors.xml=. Note
  that =$1= is always the wordform of the /central/ cohort of the
  error (so don't add =$1= as a relation). See [[*Simple grammarchecker.cg3 rules][Simple grammarchecker.cg3 rules]].

* Troubleshooting

If you get
: terminate called after throwing an instance of 'std::regex_error'
:   what():  regex_error
then your C++ compiler is too old. See [[*Prerequisites][Prerequisites]].


If you get
: configure: error: 'g++  -std=c++11 -Wall -I/usr/include/hfst/ @GLIB_CFLAGS@  -I/usr/include/ ' does not accept ISO C++11
then you may be at the receiving end of
https://github.com/hfst/hfst/issues/366. A workaround is to edit
=/usr/lib64/pkgconfig/hfst.pc= and simply delete the string
=@GLIB_CFLAGS@=.


* Progress [47/49]

=divvun-suggest= should:

- [X] read cg format
- [X] load errors.xml
- [X] load an hfstol bin
- [X] generate forms from CG-specified analyses
- [X] only generate forms if analyses have a certain tag (and don't send that tag to generator)
- [X] optionally output as JSON
- [X] handle superblanks
- [X] 4+-byte UTF-8 input
- [X] default/fallback values for ids and regexes of ids in errors.xml
- [X] flush on seeing <STREAMCMD:FLUSH>
- [X] skip @FLAGDIACRITICS@ in generator output (is there a better way than [[file:src/suggest.cpp::if(symbol.size()>0%20&&%20symbol%5B0%5D!='@')%20{][excluding symbols starting with @]]?)
- [X] deal with subreadings: http://giellatekno.uit.no/bugzilla/show_bug.cgi?id=2317#c5
- [X] input format needs to show where we have (and don't have) blanks
- [X] deal with the new blank format given by hfst-tokenise (and remove old blank hacks)
- [X] handle alternative/overlapping suggestions on the same word
- [X] handle &DELETE nicely (UI also: sihko sÃ¡ni = slett ordet)

=divvun-checker= should:

- [X] use run(stringstream, ostream) on hfst-tokenize as lib
- [X] use run(stringstream, ostream) on cg-mwesplit as lib
- [X] use run(stringstream, ostream) on vislcg3-grammar as lib
- [X] use run(stringstream, ostream) on divvun-suggest as lib
- [X] use upstream hfst ([[https://github.com/hfst/hfst/pull/352][merged]])
- [X] use upstream vislcg3, currently [[https://github.com/TinoDidriksen/cg3/issues/1][waiting on a merge]] (updated: [[https://github.com/unhammer/vislcg3/tree/StreamApplicator-merge-r12311][StreamApplicator-merge-r12311]])
- [X] read xml pipeline specification and load data based on that
- [X] allow multiple pipelines in spec
- [X] allow ignoring errors in spec
- [X] allow similar metadata to hfst-ospell (see [[https://github.com/hfst/hfst-ospell/blob/master/tests/basic_test.xml][tests/basic_test.xml]])
- [X] load PipeSpec from char buffer
- [X] load TokenizerCmd from char buffer
- [X] load MweSplitCmd from char buffer
- [X] load CGCmd from char buffer
- [X] load SuggestCmd from char buffer (HFST needs an =HfstOlInputStream(std::istream&)=)
- [X] read zip-archive like zhfst
- [X] get some API documentation
- [X] return both string and real datastructure (latter only if Suggest as last cmd)
- [X] hide implementation, make an example project using the API
- [X] travis (both Mac and Ubuntu)
- [X] link to vislcg3 without needing the source (vislcg3 has to make the functions we use available from cg3.h)
- [ ] have API for turning off sections 1/2/3/â€¦ of CG's?

=divvun-cgspell= should:

- [X] load a zhfst bin
- [X] optionally load errmodel.hfst and acceptor.hfst instead of zhfst
- [ ] Read a word per line and spell with CG output (do we still need this?)
- [X] Read CG input and spell unknown words by adding them as new readings
- [X] Read CG input and spell all words by adding them as new readings
- [X] do NUL-flushing, outputting <STREAMCMD:FLUSH>
- [X] have a timeout on generating suggestions (shouldn't use more than 0.5s per sentence?)

=divvun-blanktag= should:

- [X] load an hfst bin
- [X] Read CG input and analyse sequences of blank-wordform-blank
- [X] Put output tag of matches on each reading under the matched wf
- [X] Be usable from checker, checker-lib, apy etc., like suggest and cgspell
